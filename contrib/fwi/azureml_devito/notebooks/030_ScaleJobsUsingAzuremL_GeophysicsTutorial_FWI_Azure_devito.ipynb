{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation.  \n",
    "Licensed under the MIT License.  \n",
    "  \n",
    "\n",
    "# FWI demo based on: \n",
    "This project ports devito (https://github.com/opesci/devito) into Azure and runs tutorial notebooks at:\n",
    "https://nbviewer.jupyter.org/github/opesci/devito/blob/master/examples/seismic/tutorials/\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we run the devito demo [notebooks](https://nbviewer.jupyter.org/github/opesci/devito/blob/master/examples/seismic/tutorials/) mentioned above by using an [AzureML estimator](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.estimator.estimator?view=azure-ml-py) with custom docker image. The docker image and associated docker file were created in previous notebook.\n",
    "\n",
    "<a id='devito_in_AzureML_demoing_modes'></a>\n",
    "####   This notebook is used as a control plane to submit experimentation jobs running devito in Azure in two modes (see [remote run azureml python script file invoking devito](#devito_demo_mode)):\n",
    " - [Mode 1](#devito_demo_mode_1):\n",
    "      - uses custom code (slightly modified graphing functions save images to files too) \n",
    "      - experimentation job is defined by the devito code that is packaged as a py file to be run on an Azure remote compute target\n",
    "      - experimentation job can be used to track metrics or other artifacts (images)\n",
    "  \n",
    " - Mode 2:\n",
    "      - papermill is invoked via cli or via its Python API to run unedited devito demo notebooks (https://github.com/opesci/devito/tree/master/examples/seismic/tutorials) on the remote compute target and get back the results as saved notebooks that are then Available in Azure portal. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import shutil\n",
    "import urllib\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "\n",
    "# from azureml.core.datastore import Datastore\n",
    "# from azureml.data.data_reference import DataReference\n",
    "# from azureml.pipeline.steps import HyperDriveStep\n",
    "# from azureml.pipeline.core import Pipeline, PipelineData\n",
    "# from azureml.train.dnn import TensorFlow\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Linux-4.15.0-1064-azure-x86_64-with-debian-stretch-sid'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/datadrive01/prj/DeepSeismic/contrib/fwi/azureml_devito/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n",
    "platform.platform()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'./../not_shared/general.env'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_path_to_sys_path(path_to_append):\n",
    "    if not (any(path_to_append in paths for paths in sys.path)):\n",
    "        sys.path.append(path_to_append)\n",
    "        \n",
    "auxiliary_files_dir = os.path.join(*(['.', 'src']))\n",
    "paths_to_append = [os.path.join(os.getcwd(), auxiliary_files_dir)]\n",
    "[add_path_to_sys_path(crt_path) for crt_path in paths_to_append]\n",
    "\n",
    "import project_utils\n",
    "prj_consts = project_utils.project_consts()\n",
    "\n",
    "dotenv_file_path = os.path.join(*(prj_consts.DOTENV_FILE_PATH))\n",
    "dotenv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./../not_shared'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace_config_dir = os.path.join(*(prj_consts.AML_WORKSPACE_CONFIG_DIR))\n",
    "workspace_config_file = prj_consts.AML_WORKSPACE_CONFIG_FILE_NAME\n",
    "workspace_config_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./../temp/devito_tutorial/01_modelling.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'./../temp/devito_tutorial/azureml_01_modelling.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%dotenv $dotenv_file_path\n",
    "\n",
    "script_folder = prj_consts.AML_EXPERIMENT_DIR + ['devito_tutorial']\n",
    "\n",
    "devito_training_script_file = '01_modelling.py' # hardcoded in file azureml_training_script_full_file_name below\n",
    "azureml_training_script_file = 'azureml_'+devito_training_script_file\n",
    "experimentName = '020_AzureMLEstimator'\n",
    "\n",
    "os.makedirs(os.path.join(*(script_folder)), exist_ok=True)\n",
    "script_path = os.path.join(*(script_folder))\n",
    "training_script_full_file_name = os.path.join(script_path, devito_training_script_file)\n",
    "azureml_training_script_full_file_name = os.path.join(script_path, azureml_training_script_file)\n",
    "\n",
    "training_script_full_file_name\n",
    "azureml_training_script_full_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='devito_demo_mode_1'></a>\n",
    " \n",
    "##### devito in Azure ML demo mode 1\n",
    "Create devito demo script based on \n",
    "https://nbviewer.jupyter.org/github/opesci/devito/blob/master/examples/seismic/tutorials/01_modelling.ipynb\n",
    "\n",
    "[Back](#devito_in_AzureML_demoing_modes) to summary of modes od demoing devito in AzureML.\n",
    "\n",
    "Main purpose of this script is to extend _plot_velocity()_ and _plot_shotrecord()_ devito [plotting functions](https://github.com/opesci/devito/blob/master/examples/seismic/plotting.py) to allow the mto work in batch mode, i.e. save output to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./../temp/devito_tutorial/01_modelling.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_script_full_file_name\n",
    "\n",
    "import numpy as np\n",
    "import os, argparse\n",
    "\n",
    "from examples.seismic import Model\n",
    "from examples.seismic import TimeAxis\n",
    "from examples.seismic import Receiver\n",
    "from devito import TimeFunction\n",
    "from devito import Eq, solve\n",
    "from devito import Operator\n",
    "\n",
    "\n",
    "# try:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "mpl.rc('font', size=16)\n",
    "mpl.rc('figure', figsize=(8, 6))\n",
    "# except:\n",
    "#     plt = None\n",
    "#     cm = None\n",
    "        \n",
    "\n",
    "\n",
    "# \"all\" plotting utils in devito do not save to file, so we extend them here\n",
    "# https://github.com/opesci/devito/blob/master/examples/seismic/plotting.py\n",
    "def plot_velocity(model, source=None, receiver=None, colorbar=True, file=None):\n",
    "    \"\"\"\n",
    "    Plot a two-dimensional velocity field from a seismic `Model`\n",
    "    object. Optionally also includes point markers for sources and receivers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Model\n",
    "        Object that holds the velocity model.\n",
    "    source : array_like or float\n",
    "        Coordinates of the source point.\n",
    "    receiver : array_like or float\n",
    "        Coordinates of the receiver points.\n",
    "    colorbar : bool\n",
    "        Option to plot the colorbar.\n",
    "    \"\"\"\n",
    "    domain_size = 1.e-3 * np.array(model.domain_size)\n",
    "    extent = [model.origin[0], model.origin[0] + domain_size[0],\n",
    "              model.origin[1] + domain_size[1], model.origin[1]]\n",
    "\n",
    "    plot = plt.imshow(np.transpose(model.vp.data), animated=True, cmap=cm.jet,\n",
    "                      vmin=np.min(model.vp.data), vmax=np.max(model.vp.data),\n",
    "                      extent=extent)\n",
    "    plt.xlabel('X position (km)')\n",
    "    plt.ylabel('Depth (km)')\n",
    "\n",
    "    # Plot source points, if provided\n",
    "    if receiver is not None:\n",
    "        plt.scatter(1e-3*receiver[:, 0], 1e-3*receiver[:, 1],\n",
    "                    s=25, c='green', marker='D')\n",
    "\n",
    "    # Plot receiver points, if provided\n",
    "    if source is not None:\n",
    "        plt.scatter(1e-3*source[:, 0], 1e-3*source[:, 1],\n",
    "                    s=25, c='red', marker='o')\n",
    "\n",
    "    # Ensure axis limits\n",
    "    plt.xlim(model.origin[0], model.origin[0] + domain_size[0])\n",
    "    plt.ylim(model.origin[1] + domain_size[1], model.origin[1])\n",
    "\n",
    "    # Create aligned colorbar on the right\n",
    "    if colorbar:\n",
    "        ax = plt.gca()\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cbar = plt.colorbar(plot, cax=cax)\n",
    "        cbar.set_label('Velocity (km/s)')\n",
    "    plt.show()\n",
    "    \n",
    "    if file is not None:\n",
    "        plt.savefig(file)\n",
    "        print('plotted image saved as {} file'.format(file))\n",
    "        \n",
    "    plt.clf()\n",
    "\n",
    "def plot_shotrecord(rec, model, t0, tn, colorbar=True, file=None):\n",
    "    \"\"\"\n",
    "    Plot a shot record (receiver values over time).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rec :\n",
    "        Receiver data with shape (time, points).\n",
    "    model : Model\n",
    "        object that holds the velocity model.\n",
    "    t0 : int\n",
    "        Start of time dimension to plot.\n",
    "    tn : int\n",
    "        End of time dimension to plot.\n",
    "    \"\"\"\n",
    "    scale = np.max(rec) / 10.\n",
    "    extent = [model.origin[0], model.origin[0] + 1e-3*model.domain_size[0],\n",
    "              1e-3*tn, t0]\n",
    "\n",
    "    plot = plt.imshow(rec, vmin=-scale, vmax=scale, cmap=cm.gray, extent=extent)\n",
    "    plt.xlabel('X position (km)')\n",
    "    plt.ylabel('Time (s)')\n",
    "\n",
    "    # Create aligned colorbar on the right\n",
    "    if colorbar:\n",
    "        ax = plt.gca()\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        plt.colorbar(plot, cax=cax)\n",
    "    plt.show()   \n",
    "    \n",
    "    if file is not None:\n",
    "        plt.savefig(file)\n",
    "        print('plotted image saved as {} file'.format(file))\n",
    "        \n",
    "    plt.clf()\n",
    "\n",
    "def main(output_folder):      \n",
    "    # 1. Define the physical problem\n",
    "    # The first step is to define the physical model:\n",
    "    #  - physical dimensions of interest\n",
    "    #  - velocity profile of this physical domain\n",
    "\n",
    "    # Define a physical size\n",
    "    shape = (101, 101)  # Number of grid point (nx, nz)\n",
    "    spacing = (10., 10.)  # Grid spacing in m. The domain size is now 1km by 1km\n",
    "    origin = (0., 0.)  # What is the location of the top left corner. This is necessary to define\n",
    "    # the absolute location of the source and receivers\n",
    "\n",
    "    # Define a velocity profile. The velocity is in km/s\n",
    "    v = np.empty(shape, dtype=np.float32)\n",
    "    v[:, :51] = 1.5\n",
    "    v[:, 51:] = 2.5\n",
    "\n",
    "    # With the velocity and model size defined, we can create the seismic model that\n",
    "    # encapsulates this properties. We also define the size of the absorbing layer as 10 grid points\n",
    "    model = Model(vp=v, origin=origin, shape=shape, spacing=spacing,\n",
    "                  space_order=2, nbpml=10)\n",
    "\n",
    "    plot_velocity(model, \n",
    "              file= os.path.join(*( [output_folder,'output000.png'])))\n",
    "    \n",
    "    # 2. Acquisition geometry\n",
    "    t0 = 0.  # Simulation starts a t=0\n",
    "    tn = 1000.  # Simulation last 1 second (1000 ms)\n",
    "    dt = model.critical_dt  # Time step from model grid spacing\n",
    "\n",
    "    time_range = TimeAxis(start=t0, stop=tn, step=dt)\n",
    "    from examples.seismic import RickerSource\n",
    "\n",
    "    f0 = 0.010  # Source peak frequency is 10Hz (0.010 kHz)\n",
    "    src = RickerSource(name='src', grid=model.grid, f0=f0,\n",
    "                       npoint=1, time_range=time_range)\n",
    "\n",
    "    # First, position source centrally in all dimensions, then set depth\n",
    "    src.coordinates.data[0, :] = np.array(model.domain_size) * .5\n",
    "    src.coordinates.data[0, -1] = 20.  # Depth is 20m\n",
    "\n",
    "    # We can plot the time signature to see the wavelet\n",
    "#     src.show()\n",
    "\n",
    "    # Create symbol for 101 receivers\n",
    "    rec = Receiver(name='rec', grid=model.grid, npoint=101, time_range=time_range)\n",
    "\n",
    "    # Prescribe even spacing for receivers along the x-axis\n",
    "    rec.coordinates.data[:, 0] = np.linspace(0, model.domain_size[0], num=101)\n",
    "    rec.coordinates.data[:, 1] = 20.  # Depth is 20m\n",
    "\n",
    "    # We can now show the source and receivers within our domain:\n",
    "    # Red dot: Source location\n",
    "    # Green dots: Receiver locations (every 4th point)\n",
    "    plot_velocity(model, source=src.coordinates.data,\n",
    "                  receiver=rec.coordinates.data[::4, :], \n",
    "              file= os.path.join(*( [output_folder,'output010.png'])))\n",
    "    \n",
    "    # Define the wavefield with the size of the model and the time dimension\n",
    "    u = TimeFunction(name=\"u\", grid=model.grid, time_order=2, space_order=2)\n",
    "\n",
    "    # We can now write the PDE\n",
    "    pde = model.m * u.dt2 - u.laplace + model.damp * u.dt\n",
    "\n",
    "    # The PDE representation is as on paper\n",
    "    pde\n",
    "    \n",
    "    # This discrete PDE can be solved in a time-marching way updating u(t+dt) from the previous time step\n",
    "    # Devito as a shortcut for u(t+dt) which is u.forward. We can then rewrite the PDE as \n",
    "    # a time marching updating equation known as a stencil using customized SymPy functions\n",
    "\n",
    "    stencil = Eq(u.forward, solve(pde, u.forward))\n",
    "    # Finally we define the source injection and receiver read function to generate the corresponding code\n",
    "    src_term = src.inject(field=u.forward, expr=src * dt**2 / model.m)\n",
    "\n",
    "    # Create interpolation expression for receivers\n",
    "    rec_term = rec.interpolate(expr=u.forward)\n",
    "\n",
    "    op = Operator([stencil] + src_term + rec_term, subs=model.spacing_map)\n",
    "    \n",
    "    op(time=time_range.num-1, dt=model.critical_dt)\n",
    "    plot_shotrecord(rec.data, model, t0, tn, \n",
    "              file= os.path.join(*( [output_folder,'output020.png'])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--output_folder', type=str, nargs='?', \\\n",
    "                        dest='output_folder', help='ouput artifacts location',\\\n",
    "                       default='.')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args.output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get experimentation docker image for devito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fwi01_azureml:sdk.v1.0.79'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'fwi01acr.azurecr.io/fwi01_azureml:sdk.v1.0.79'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo_name = os.getenv('ACR_NAME')+'.azurecr.io' # or os.getenv('DOCKER_LOGIN')\n",
    "\n",
    "docker_image_name = os.getenv('EXPERIMENTATION_DOCKER_IMAGE_NAME')\n",
    "\n",
    "image_version = os.getenv('EXPERIMENTATION_DOCKER_IMAGE_TAG')\n",
    "if image_version!=\"\":\n",
    "    docker_image_name = docker_image_name +':'+ image_version\n",
    "\n",
    "full_docker_image_name = docker_repo_name + '/' + docker_image_name\n",
    "    \n",
    "docker_image_name\n",
    "full_docker_image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract/decide the python path in custom docker image that corresponds to desired conda environment. Without this, AzureML tries to create a separate environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docker run -i --rm  --name fwi01_azureml_container02 fwi01acr.azurecr.io/fwi01_azureml:sdk.v1.0.79 /bin/bash -c \"which python\" '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/opt/conda/envs/fwi01_conda_env/bin/python'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Python_path_command='docker run -i --rm  --name fwi01_azureml_container02 '+ \\\n",
    "full_docker_image_name + \\\n",
    "' /bin/bash -c \"which python\" '\n",
    "get_Python_path_command\n",
    "\n",
    "\n",
    "import subprocess\n",
    "python_path_in_docker_image = subprocess.check_output(get_Python_path_command,shell=True,stderr=subprocess.STDOUT).\\\n",
    "decode('utf-8').strip()\n",
    "python_path_in_docker_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='devito_demo_mode'></a>\n",
    "#### Create azureml_script_file that invokes:\n",
    " - devito exclusive custom edited training_script_file\n",
    " - unedited devito notebooks via papermill (invoked via cli and via ppapermill python API)\n",
    "\n",
    "[Back](#devito_in_AzureML_demoing_modes) to notebook summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./../temp/devito_tutorial/azureml_01_modelling.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $azureml_training_script_full_file_name\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.system('conda env list')\n",
    "\n",
    "import azureml.core;\n",
    "from azureml.core.run import Run\n",
    "\n",
    "print(azureml.core.VERSION)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', help='ouput artifacts location')\n",
    "\n",
    "args = parser.parse_args()\n",
    "print('args.output_folder is {} but it will be ignored since AzureML_tracked ./outputs will be used'.format(args.output_folder))\n",
    "\n",
    "# get the Azure ML run object\n",
    "run = Run.get_context()\n",
    "\n",
    "# ./outputs/ folder is autotracked so should get uploaded at the end of the run\n",
    "output_dir_AzureML_tracked = './outputs'\n",
    "\n",
    "crt_dir = os.getcwd()\n",
    "\n",
    "cli_command= \\\n",
    "'cd /devito; /opt/conda/envs/fwi01_conda_env/bin/python '+ crt_dir +'/01_modelling.py' + \\\n",
    "' --output_folder '+ crt_dir + output_dir_AzureML_tracked+ '/' + \\\n",
    "' > '+ crt_dir + output_dir_AzureML_tracked + '/01_modelling.log' \n",
    "# + \\\n",
    "# ' 2>&1 ' + crt_dir +'/'+ output_dir_AzureML_tracked + '/devito_cli_py.log'\n",
    "print('Running devito from cli on 01_modelling.py----BEGIN-----:') \n",
    "print(cli_command); print('\\n');os.system(cli_command)\n",
    "print('Running devito from cli on 01_modelling.py----END-----:\\n\\n')\n",
    "\n",
    "cli_command= \\\n",
    "'cd /devito; papermill ' + \\\n",
    "'./examples/seismic/tutorials/02_rtm.ipynb '+\\\n",
    "crt_dir +'/outputs/02_rtm_output.ipynb  ' + \\\n",
    "'--log-output  --no-progress-bar  --kernel python3 ' + \\\n",
    "' > '+ crt_dir + output_dir_AzureML_tracked + '/02_rtm_output.log' \n",
    "# + \\\n",
    "# ' 2>&1 ' + crt_dir +'/'+ output_dir_AzureML_tracked + '/papermill_cli.log'\n",
    "\n",
    "# FIXME - activate right conda env for running papermill from cli\n",
    "activate_right_conda_env_fixed = False\n",
    "if activate_right_conda_env_fixed:\n",
    "    print('Running papermill from cli on 02_rtm.ipynb----BEGIN-----:') \n",
    "    print(cli_command); print('\\n');os.system(cli_command)\n",
    "    print('Running papermill from cli on 02_rtm.ipynb----END-----:\\n\\n') \n",
    "\n",
    "\n",
    "print('Running papermill from Python API on 03_fwi.ipynb----BEGIN-----:') \n",
    "import papermill as pm\n",
    "os.chdir('/devito')\n",
    "pm.execute_notebook(\n",
    "   './examples/seismic/tutorials/03_fwi.ipynb',\n",
    "   crt_dir +'/outputs/03_fwi_output.ipynb'\n",
    ")\n",
    "print('Running papermill from Python API on 03_fwi.ipynb----END-----:') \n",
    "\n",
    "print('Running papermill from Python API on 04_dask.ipynb----BEGIN-----:') \n",
    "import papermill as pm\n",
    "os.chdir('/devito')\n",
    "pm.execute_notebook(\n",
    "   './examples/seismic/tutorials/04_dask.ipynb',\n",
    "   crt_dir +'/outputs/04_dask_output.ipynb'\n",
    ")\n",
    "print('Running papermill from Python API on 04_dask.ipynb----END-----:') \n",
    " \n",
    "\n",
    "os.system('pwd')\n",
    "os.system('ls -l /')\n",
    "os.system('ls -l ./')\n",
    "os.system('ls -l ' +crt_dir + output_dir_AzureML_tracked)\n",
    "run.log('training_message01: ', 'finished experiment')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml_01_modelling.py', '01_modelling.py']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_path=os.path.join(*(script_folder))\n",
    "os.listdir(script_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration. If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure the config file is present at .\\config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: ghiordanfwiws\n",
      "Azure region: eastus2\n",
      "Subscription id: 7899\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config(\n",
    "    path=os.path.join(os.getcwd(),\n",
    "                      os.path.join(*([workspace_config_dir, '.azureml', workspace_config_file]))))\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id[0:4], sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an experiment named \"tf-mnist\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name=experimentName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve or create a Azure Machine Learning compute\n",
    "Azure Machine Learning Compute is a service for provisioning and managing clusters of Azure virtual machines for running machine learning workloads. Let's create a new Azure Machine Learning Compute in the current workspace, if it doesn't already exist. We will then run the training script on this compute target.\n",
    "\n",
    "If we could not find the compute with the given name in the previous cell, then we will create a new compute here. This process is broken down into the following steps:\n",
    "\n",
    "1. Create the configuration\n",
    "2. Create the Azure Machine Learning compute\n",
    "\n",
    "**This process will take a few minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpuclstfwi07'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_cluster_name = os.getenv('GPU_CLUSTER_NAME')\n",
    "gpu_cluster_name = 'gpuclstfwi07'\n",
    "gpu_cluster_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing gpu cluster\n"
     ]
    }
   ],
   "source": [
    "# Verify that cluster does not exist already\n",
    "max_nodes_value = 2\n",
    "try:\n",
    "    gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print(\"Found existing gpu cluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Could not find ComputeTarget cluster!\")\n",
    "    \n",
    "# #     Create a new gpucluster using code below\n",
    "#     # Specify the configuration for the new cluster\n",
    "#     compute_config = AmlCompute.provisioning_configuration(vm_size=\"Standard_NC6\",\n",
    "#                                                            min_nodes=0,\n",
    "#                                                            max_nodes=max_nodes_value)\n",
    "#     # Create the cluster with the specified name and configuration\n",
    "#     gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "\n",
    "#     # Wait for the cluster to complete, show the output log\n",
    "#     gpu_cluster.wait_for_completion(show_output=True)\n",
    "    \n",
    "    \n",
    "#     for demo purposes, show how clsuter properties can be altered post-creation\n",
    "gpu_cluster.update(min_nodes=0, max_nodes=max_nodes_value, idle_seconds_before_scaledown=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Azure ML SDK estimator with custom docker image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521e64911a6d4083888e995ff79da564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/020_AzureMLEstimator/runs/020_AzureMLEstimator_1576639227_6528b852?wsid=/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourcegroups/ghiordanfwirsg01/workspaces/ghiordanfwiws\", \"run_id\": \"020_AzureMLEstimator_1576639227_6528b852\", \"run_properties\": {\"run_id\": \"020_AzureMLEstimator_1576639227_6528b852\", \"created_utc\": \"2019-12-18T03:20:30.235502Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"a5071b2a-37a7-40da-8340-69cc894091cb\", \"azureml.git.repository_uri\": \"git@github.com:georgeAccnt-GH/DeepSeismic.git\", \"mlflow.source.git.repoURL\": \"git@github.com:georgeAccnt-GH/DeepSeismic.git\", \"azureml.git.branch\": \"ghiordan/azureml_devito03\", \"mlflow.source.git.branch\": \"ghiordan/azureml_devito03\", \"azureml.git.commit\": \"335e90f9a770fb28b62e509c433421a92cbb8934\", \"mlflow.source.git.commit\": \"335e90f9a770fb28b62e509c433421a92cbb8934\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2019-12-18T03:22:33.515195Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576639227_6528b852/azureml-logs/55_azureml-execution-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt?sv=2019-02-02&sr=b&sig=wEJg5h%2FN%2BCt%2BavdQxsl%2BlSnQqqxmd8500luwM1gktnk%3D&st=2019-12-18T03%3A12%3A38Z&se=2019-12-18T11%3A22%3A38Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576639227_6528b852/azureml-logs/65_job_prep-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt?sv=2019-02-02&sr=b&sig=cMfZVjgZuTxt3xBtMpsCQeIJ%2BVQmH%2FdalkHgyged5ow%3D&st=2019-12-18T03%3A12%3A38Z&se=2019-12-18T11%3A22%3A38Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576639227_6528b852/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=O59A3Pe3NfBZ%2Bm7z3Z4WB69ZE60K3qlNPb%2BCO6NV7Dw%3D&st=2019-12-18T03%3A12%3A38Z&se=2019-12-18T11%3A22%3A38Z&sp=r\", \"azureml-logs/75_job_post-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576639227_6528b852/azureml-logs/75_job_post-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt?sv=2019-02-02&sr=b&sig=qj3UaXzOtJWiFXaT%2FYy%2BrBj3X14pYuekf8cZDbrQiHY%3D&st=2019-12-18T03%3A12%3A38Z&se=2019-12-18T11%3A22%3A38Z&sp=r\", \"azureml-logs/process_info.json\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576639227_6528b852/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=eImLU0mmrY4KANoEJL%2FXEFaOm%2Fp5%2F8StuxJdfr2URjY%3D&st=2019-12-18T03%3A12%3A38Z&se=2019-12-18T11%3A22%3A38Z&sp=r\", \"azureml-logs/process_status.json\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576639227_6528b852/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=t9NdOE5AOFhCK%2BqSNfJs51l2Zn3Z9Mx8vYDaiR0wNUU%3D&st=2019-12-18T03%3A12%3A38Z&se=2019-12-18T11%3A22%3A38Z&sp=r\", \"logs/azureml/688_azureml.log\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576639227_6528b852/logs/azureml/688_azureml.log?sv=2019-02-02&sr=b&sig=ju9O1BPKJ16IKUYN4fEHv%2BHBTTdruFSD%2FRyKBT1zbPI%3D&st=2019-12-18T03%3A12%3A38Z&se=2019-12-18T11%3A22%3A38Z&sp=r\", \"logs/azureml/azureml.log\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576639227_6528b852/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=HV5hFHBamtTh7MaJ%2Fcq56Hssz6QPNlbXvrjz1T1KOTA%3D&st=2019-12-18T03%3A12%3A38Z&se=2019-12-18T11%3A22%3A38Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\"], [\"logs/azureml/688_azureml.log\"]], \"run_duration\": \"0:02:03\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"training_message01: \", \"run_id\": \"020_AzureMLEstimator_1576639227_6528b852\", \"categories\": [0], \"series\": [{\"data\": [\"finished experiment\"]}]}], \"run_logs\": \"2019-12-18 03:20:52,190|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2019-12-18 03:20:52,190|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2019-12-18 03:20:52,191|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2019-12-18 03:20:52,191|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2019-12-18 03:20:52,458|azureml._base_sdk_common.user_agent|DEBUG|Fetching client info from /root/.azureml/clientinfo.json\\n2019-12-18 03:20:52,459|azureml._base_sdk_common.user_agent|DEBUG|Error loading client info: [Errno 2] No such file or directory: '/root/.azureml/clientinfo.json'\\n2019-12-18 03:20:52,795|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2019-12-18 03:20:52,796|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2019-12-18 03:20:52,796|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2019-12-18 03:20:52,796|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2019-12-18 03:20:52,796|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7ffbf430e598> for run source hyperdrive\\n2019-12-18 03:20:53,320|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x7ffbdd56d510> for run source azureml.PipelineRun\\n2019-12-18 03:20:53,324|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x7ffbdd56df28> for run source azureml.ReusedStepRun\\n2019-12-18 03:20:53,328|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x7ffbdd56dea0> for run source azureml.StepRun\\n2019-12-18 03:20:53,332|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7ffbf4441bf8> for run source azureml.scriptrun\\n2019-12-18 03:20:53,333|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-18 03:20:53,338|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:53,339|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2019-12-18 03:20:53,339|azureml.core.authentication|DEBUG|Time to expire 1814376.660805 seconds\\n2019-12-18 03:20:53,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,339|azureml._base_sdk_common.service_discovery|DEBUG|Constructing mms service url in from history url environment variable None, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,339|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,340|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,368|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:53,372|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:53,378|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:53,382|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:53,387|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:53,391|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:53,391|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2019-12-18 03:20:53,392|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-18 03:20:53,392|msrest.http_logger|DEBUG|Request URL: 'https://eastus2.experiments.azureml.net/history/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runs/020_AzureMLEstimator_1576639227_6528b852'\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|Request method: 'GET'\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|Request headers:\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '9ba8101b-982f-4288-b938-521153e4955e'\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|    'request-id': '9ba8101b-982f-4288-b938-521153e4955e'\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1057-azure-x86_64-with-debian-10.1) msrest/0.6.10 azureml._restclient/core.1.0.79'\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|Request body:\\n2019-12-18 03:20:53,393|msrest.http_logger|DEBUG|None\\n2019-12-18 03:20:53,393|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-18 03:20:53,393|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-18 03:20:53,393|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-18 03:20:53,393|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-18 03:20:53,555|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-18 03:20:53,555|msrest.http_logger|DEBUG|Response headers:\\n2019-12-18 03:20:53,555|msrest.http_logger|DEBUG|    'Date': 'Wed, 18 Dec 2019 03:20:53 GMT'\\n2019-12-18 03:20:53,555|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-18 03:20:53,555|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2019-12-18 03:20:53,555|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '9ba8101b-982f-4288-b938-521153e4955e'\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|Response content:\\n2019-12-18 03:20:53,556|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 5540,\\n  \\\"rootRunId\\\": \\\"020_AzureMLEstimator_1576639227_6528b852\\\",\\n  \\\"experimentId\\\": \\\"8d96276b-f420-4a67-86be-f933dd3d38cd\\\",\\n  \\\"createdUtc\\\": \\\"2019-12-18T03:20:30.2355028+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"b77869a0-66f2-4288-89ef-13c10accc4dc\\\",\\n    \\\"userPuId\\\": \\\"1003000090A95868\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\\\",\\n    \\\"userTenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\",\\n    \\\"userName\\\": \\\"George Iordanescu\\\"\\n  },\\n  \\\"userId\\\": \\\"b77869a0-66f2-4288-89ef-13c10accc4dc\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": null,\\n  \\\"revision\\\": 7,\\n  \\\"runId\\\": \\\"020_AzureMLEstimator_1576639227_6528b852\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2019-12-18T03:20:43.031023+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.020_AzureMLEstimator_1576639227_6528b852\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"a5071b2a-37a7-40da-8340-69cc894091cb\\\",\\n    \\\"azureml.git.repository_uri\\\": \\\"git@github.com:georgeAccnt-GH/DeepSeismic.git\\\",\\n    \\\"mlflow.source.git.repoURL\\\": \\\"git@github.com:georgeAccnt-GH/DeepSeismic.git\\\",\\n    \\\"azureml.git.branch\\\": \\\"ghiordan/azureml_devito03\\\",\\n    \\\"mlflow.source.git.branch\\\": \\\"ghiordan/azureml_devito03\\\",\\n    \\\"azureml.git.commit\\\": \\\"335e90f9a770fb28b62e509c433421a92cbb8934\\\",\\n    \\\"mlflow.source.git.commit\\\": \\\"335e90f9a770fb28b62e509c433421a92cbb8934\\\",\\n    \\\"azureml.git.dirty\\\": \\\"True\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"azureml_01_modelling.py\\\",\\n  \\\"target\\\": \\\"gpuclstfwi07\\\",\\n  \\\"tags\\\": {},\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": {\\n    \\\"type\\\": \\\"Notebook\\\",\\n    \\\"locationType\\\": \\\"ArtifactId\\\",\\n    \\\"location\\\": \\\"LocalUpload/020_AzureMLEstimator_1576639227_6528b852/030_ScaleJobsUsingAzuremL_GeophysicsTutorial_FWI_Azure_devito.ipynb\\\"\\n  },\\n  \\\"cancelUri\\\": \\\"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runId/020_AzureMLEstimator_1576639227_6528b852/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runId/020_AzureMLEstimator_1576639227_6528b852/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false,\\n  \\\"queueingInfo\\\": null\\n}\\n2019-12-18 03:20:53,561|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2019-12-18 03:20:53,562|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'a5071b2a-37a7-40da-8340-69cc894091cb', 'azureml.git.repository_uri': 'git@github.com:georgeAccnt-GH/DeepSeismic.git', 'mlflow.source.git.repoURL': 'git@github.com:georgeAccnt-GH/DeepSeismic.git', 'azureml.git.branch': 'ghiordan/azureml_devito03', 'mlflow.source.git.branch': 'ghiordan/azureml_devito03', 'azureml.git.commit': '335e90f9a770fb28b62e509c433421a92cbb8934', 'mlflow.source.git.commit': '335e90f9a770fb28b62e509c433421a92cbb8934', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2019-12-18 03:20:53,562|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2019-12-18 03:20:53,562|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2019-12-18 03:20:53,563|azureml.WorkerPool|DEBUG|[START]\\n2019-12-18 03:20:53,563|azureml.SendRunKillSignal|DEBUG|[START]\\n2019-12-18 03:20:53,563|azureml.RunStatusContext|DEBUG|[START]\\n2019-12-18 03:20:53,563|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunContextManager.RunStatusContext|DEBUG|[START]\\n2019-12-18 03:20:53,563|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2019-12-18 03:20:53,563|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2019-12-18 03:20:53,563|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/ghiordanfwiws/azureml/020_azuremlestimator_1576639227_6528b852/mounts/workspaceblobstore/azureml/020_AzureMLEstimator_1576639227_6528b852\\n2019-12-18 03:20:53,563|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2019-12-18 03:20:53,563|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/ghiordanfwiws/azureml/020_azuremlestimator_1576639227_6528b852/mounts/workspaceblobstore/azureml/020_AzureMLEstimator_1576639227_6528b852\\n2019-12-18 03:20:55,880|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,880|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,880|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,880|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,880|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,880|azureml._base_sdk_common.service_discovery|DEBUG|Constructing mms service url in from history url environment variable None, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,881|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,881|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,881|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:20:55,886|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:55,887|azureml._run_impl.run_history_facade|DEBUG|Created a static thread pool for RunHistoryFacade class\\n2019-12-18 03:20:55,892|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:55,897|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:55,901|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:55,906|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:20:55,906|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2019-12-18 03:20:55,906|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|Request URL: 'https://eastus2.experiments.azureml.net/history/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runs/020_AzureMLEstimator_1576639227_6528b852'\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|Request method: 'GET'\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|Request headers:\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'b5b744e6-b6a5-4eb8-b360-e0f471c112b4'\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|    'request-id': 'b5b744e6-b6a5-4eb8-b360-e0f471c112b4'\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1057-azure-x86_64-with-debian-10.1) msrest/0.6.10 azureml._restclient/core.1.0.79'\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|Request body:\\n2019-12-18 03:20:55,907|msrest.http_logger|DEBUG|None\\n2019-12-18 03:20:55,907|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-18 03:20:55,907|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-18 03:20:55,907|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-18 03:20:55,908|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-18 03:20:55,964|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-18 03:20:55,964|msrest.http_logger|DEBUG|Response headers:\\n2019-12-18 03:20:55,964|msrest.http_logger|DEBUG|    'Date': 'Wed, 18 Dec 2019 03:20:55 GMT'\\n2019-12-18 03:20:55,964|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-18 03:20:55,964|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2019-12-18 03:20:55,964|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'b5b744e6-b6a5-4eb8-b360-e0f471c112b4'\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|Response content:\\n2019-12-18 03:20:55,965|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 5540,\\n  \\\"rootRunId\\\": \\\"020_AzureMLEstimator_1576639227_6528b852\\\",\\n  \\\"experimentId\\\": \\\"8d96276b-f420-4a67-86be-f933dd3d38cd\\\",\\n  \\\"createdUtc\\\": \\\"2019-12-18T03:20:30.2355028+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"b77869a0-66f2-4288-89ef-13c10accc4dc\\\",\\n    \\\"userPuId\\\": \\\"1003000090A95868\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\\\",\\n    \\\"userTenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\",\\n    \\\"userName\\\": \\\"George Iordanescu\\\"\\n  },\\n  \\\"userId\\\": \\\"b77869a0-66f2-4288-89ef-13c10accc4dc\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": null,\\n  \\\"revision\\\": 7,\\n  \\\"runId\\\": \\\"020_AzureMLEstimator_1576639227_6528b852\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2019-12-18T03:20:43.031023+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.020_AzureMLEstimator_1576639227_6528b852\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"a5071b2a-37a7-40da-8340-69cc894091cb\\\",\\n    \\\"azureml.git.repository_uri\\\": \\\"git@github.com:georgeAccnt-GH/DeepSeismic.git\\\",\\n    \\\"mlflow.source.git.repoURL\\\": \\\"git@github.com:georgeAccnt-GH/DeepSeismic.git\\\",\\n    \\\"azureml.git.branch\\\": \\\"ghiordan/azureml_devito03\\\",\\n    \\\"mlflow.source.git.branch\\\": \\\"ghiordan/azureml_devito03\\\",\\n    \\\"azureml.git.commit\\\": \\\"335e90f9a770fb28b62e509c433421a92cbb8934\\\",\\n    \\\"mlflow.source.git.commit\\\": \\\"335e90f9a770fb28b62e509c433421a92cbb8934\\\",\\n    \\\"azureml.git.dirty\\\": \\\"True\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"azureml_01_modelling.py\\\",\\n  \\\"target\\\": \\\"gpuclstfwi07\\\",\\n  \\\"tags\\\": {},\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": {\\n    \\\"type\\\": \\\"Notebook\\\",\\n    \\\"locationType\\\": \\\"ArtifactId\\\",\\n    \\\"location\\\": \\\"LocalUpload/020_AzureMLEstimator_1576639227_6528b852/030_ScaleJobsUsingAzuremL_GeophysicsTutorial_FWI_Azure_devito.ipynb\\\"\\n  },\\n  \\\"cancelUri\\\": \\\"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runId/020_AzureMLEstimator_1576639227_6528b852/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runId/020_AzureMLEstimator_1576639227_6528b852/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false,\\n  \\\"queueingInfo\\\": null\\n}\\n2019-12-18 03:20:55,968|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2019-12-18 03:20:55,968|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'a5071b2a-37a7-40da-8340-69cc894091cb', 'azureml.git.repository_uri': 'git@github.com:georgeAccnt-GH/DeepSeismic.git', 'mlflow.source.git.repoURL': 'git@github.com:georgeAccnt-GH/DeepSeismic.git', 'azureml.git.branch': 'ghiordan/azureml_devito03', 'mlflow.source.git.branch': 'ghiordan/azureml_devito03', 'azureml.git.commit': '335e90f9a770fb28b62e509c433421a92cbb8934', 'mlflow.source.git.commit': '335e90f9a770fb28b62e509c433421a92cbb8934', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2019-12-18 03:20:55,968|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2019-12-18 03:21:23,334|azureml.core.authentication|DEBUG|Time to expire 1814346.666025 seconds\\n2019-12-18 03:21:53,334|azureml.core.authentication|DEBUG|Time to expire 1814316.665578 seconds\\n2019-12-18 03:22:06,840|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2019-12-18 03:22:06,840|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-18 03:22:06,841|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2019-12-18 03:22:07,052|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2019-12-18 03:22:07,052|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /devito\\n2019-12-18 03:22:07,052|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|pyfs has path /devito\\n2019-12-18 03:22:07,052|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /devito to /mnt/batch/tasks/shared/LS_root/jobs/ghiordanfwiws/azureml/020_azuremlestimator_1576639227_6528b852/mounts/workspaceblobstore/azureml/020_AzureMLEstimator_1576639227_6528b852\\n2019-12-18 03:22:07,052|azureml.history._tracking.PythonWorkingDirectory|INFO|Setting working dir to /mnt/batch/tasks/shared/LS_root/jobs/ghiordanfwiws/azureml/020_azuremlestimator_1576639227_6528b852/mounts/workspaceblobstore/azureml/020_AzureMLEstimator_1576639227_6528b852\\n2019-12-18 03:22:07,052|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2019-12-18 03:22:07,053|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2019-12-18 03:22:07,053|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852|INFO|complete is not setting status for submitted runs.\\n2019-12-18 03:22:07,053|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-18 03:22:07,053|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2019-12-18 03:22:07,053|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-18 03:22:07,054|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2019-12-18 03:22:07,054|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-18 03:22:07,054|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2019-12-18 03:22:07,054|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2019-12-18 03:22:07,054|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2019-12-18 03:22:07,054|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-18 03:22:07,054|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-18 03:22:07,054|azureml.RunStatusContext|DEBUG|[STOP]\\n2019-12-18 03:22:07,055|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-18 03:22:07,055|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-18 03:22:07,055|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2019-12-18 03:22:07,055|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2019-12-18 03:22:07,055|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2019-12-18 03:22:07,055|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-18 03:22:07,055|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-18 03:22:07,055|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-18 03:22:07,055|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2019-12-18 03:22:07,055|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2019-12-18 03:22:07,056|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 1.\\n2019-12-18 03:22:07,056|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2019-12-18 03:22:07,056|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2019-12-18 03:22:07,056|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2019-12-18 03:22:07,057|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2019-12-18 03:22:07,057|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch|DEBUG|Using basic handler - no exception handling\\n2019-12-18 03:22:07,057|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2019-12-18 03:22:07,058|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-18 03:22:07,058|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 0__log_batch to queue of approximate size: 0\\n2019-12-18 03:22:07,058|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2019-12-18 03:22:07,059|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:22:07,059|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2019-12-18 03:22:07,059|msrest.http_logger|DEBUG|Request URL: 'https://eastus2.experiments.azureml.net/history/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runs/020_AzureMLEstimator_1576639227_6528b852/batch/metrics'\\n2019-12-18 03:22:07,059|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2019-12-18 03:22:07,059|msrest.http_logger|DEBUG|Request method: 'POST'\\n2019-12-18 03:22:07,059|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2019-12-18 03:22:07,060|msrest.http_logger|DEBUG|Request headers:\\n2019-12-18 03:22:07,060|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2019-12-18 03:22:07,060|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-18 03:22:07,060|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2019-12-18 03:22:07,060|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2019-12-18 03:22:07,060|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2019-12-18 03:22:07,060|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'f3fe67d8-6f74-4c18-8a93-845b18aca364'\\n2019-12-18 03:22:07,060|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2019-12-18 03:22:07,060|msrest.http_logger|DEBUG|    'request-id': 'f3fe67d8-6f74-4c18-8a93-845b18aca364'\\n2019-12-18 03:22:07,060|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-18 03:22:07,061|msrest.http_logger|DEBUG|    'Content-Length': '410'\\n2019-12-18 03:22:07,061|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2019-12-18 03:22:07,061|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1057-azure-x86_64-with-debian-10.1) msrest/0.6.10 azureml._restclient/core.1.0.79 sdk_run'\\n2019-12-18 03:22:07,061|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [AsyncTask(0__log_batch)].\\n2019-12-18 03:22:07,061|msrest.http_logger|DEBUG|Request body:\\n2019-12-18 03:22:07,061|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"85c6d826-5d8d-4ec9-9ac2-20ebbc1af5a3\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2019-12-18T03:22:06.840237Z\\\", \\\"name\\\": \\\"training_message01: \\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"training_message01: \\\": \\\"finished experiment\\\"}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"training_message01: \\\", \\\"name\\\": \\\"training_message01: \\\", \\\"type\\\": \\\"string\\\"}]}}]}\\n2019-12-18 03:22:07,061|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-18 03:22:07,061|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-18 03:22:07,061|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-18 03:22:07,062|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-18 03:22:07,321|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-18 03:22:07,321|msrest.http_logger|DEBUG|Response headers:\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|    'Date': 'Wed, 18 Dec 2019 03:22:07 GMT'\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'f3fe67d8-6f74-4c18-8a93-845b18aca364'\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|Response content:\\n2019-12-18 03:22:07,322|msrest.http_logger|DEBUG|\\n2019-12-18 03:22:07,323|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2019-12-18 03:22:07,562|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|[START]\\n2019-12-18 03:22:07,562|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|Awaiter is PostMetricsBatch\\n2019-12-18 03:22:07,562|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|[STOP]\\n2019-12-18 03:22:07,562|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Waiting on task: 0__log_batch.\\n1 tasks left. Current duration of flush 0.00022602081298828125 seconds.\\nWaiting on task: 0__log_batch.\\n1 tasks left. Current duration of flush 0.2506241798400879 seconds.\\n\\n2019-12-18 03:22:07,563|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-18 03:22:07,563|azureml._SubmittedRun#020_AzureMLEstimator_1576639227_6528b852.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-18 03:22:07,563|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2019-12-18 03:22:07,563|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2019-12-18 03:22:07,563|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2019-12-18 03:22:07,563|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"NOTSET\", \"sdk_version\": \"1.0.76\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use a custom Docker image\n",
    "from azureml.core.container_registry import ContainerRegistry\n",
    "\n",
    "image_name = docker_image_name\n",
    "\n",
    "# you can also point to an image in a private ACR\n",
    "image_registry_details = ContainerRegistry()\n",
    "image_registry_details.address = docker_repo_name\n",
    "image_registry_details.username = os.getenv('ACR_USERNAME')\n",
    "image_registry_details.password = os.getenv('ACR_PASSWORD') \n",
    "\n",
    "# don't let the system build a new conda environment\n",
    "user_managed_dependencies = True\n",
    "\n",
    "# submit to a local Docker container. if you don't have Docker engine running locally, you can set compute_target to cpu_cluster.\n",
    "script_params = {\n",
    "        '--output_folder': 'some_folder'\n",
    "}\n",
    "\n",
    "\n",
    "# distributed_training_conf = MpiConfiguration()\n",
    "# distributed_training_conf.process_count_per_node = 2\n",
    "\n",
    "est = Estimator(source_directory=script_path, \n",
    "                compute_target=gpu_cluster,#'local', #gpu_cluster, \n",
    "                entry_script=azureml_training_script_file,\n",
    "                script_params=script_params,\n",
    "                use_docker=True,\n",
    "                custom_docker_image=image_name,\n",
    "                # uncomment below line to use your private ACR\n",
    "                image_registry_details=image_registry_details, \n",
    "                user_managed=user_managed_dependencies,\n",
    "                distributed_training=None,\n",
    "                node_count=1\n",
    "                )\n",
    "est.run_config.environment.python.interpreter_path = python_path_in_docker_image\n",
    "\n",
    "run = exp.submit(est)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use the above link to currrent experiment run in Azure Portal to see tracked metrics, and images and output notebooks saved by azureml_training_script_full_file_name in {run_dir}/outputs on the remote compute target that are automatically saved by AzureML in the run history Azure portal pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final print 10, time 21.283 seconds: Counter({'Completed': 1})\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "#wait till all jobs finished\n",
    "\n",
    "def wait_for_run_list_to_finish(the_run_list):\n",
    "    finished_status_list = ['Completed', 'Failed']\n",
    "    printing_counter = 0\n",
    "    start_time = time.time()\n",
    "    while (not all((crt_queried_job.get_status() in finished_status_list) for crt_queried_job in the_run_list)):\n",
    "        time.sleep(2)\n",
    "        printing_counter+= 1\n",
    "        print('print {0:.0f}, time {1:.3f} seconds: {2}'.format(printing_counter, time.time() - start_time, \n",
    "                                str(Counter([crt_queried_job.get_status() for crt_queried_job in the_run_list]))), end=\"\\r\")\n",
    "#     final status\n",
    "    print('Final print {0:.0f}, time {1:.3f} seconds: {2}'.format(printing_counter, time.time() - start_time, \n",
    "                                str(Counter([crt_queried_job.get_status() for crt_queried_job in the_run_list]))), end=\"\\r\")     \n",
    "wait_for_run_list_to_finish([run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_duration in seconds 110.484172\n",
      "run_duration= 1m 50.484s\n"
     ]
    }
   ],
   "source": [
    "import datetime, math\n",
    "def get_run_duration(azureml_exp_run):\n",
    "    run_details =  azureml_exp_run.get_details()\n",
    "    run_duration = datetime.datetime.strptime(run_details['endTimeUtc'], \"%Y-%m-%dT%H:%M:%S.%fZ\") - \\\n",
    "               datetime.datetime.strptime(run_details['startTimeUtc'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    return run_duration.total_seconds()\n",
    "run_duration = get_run_duration(run)\n",
    "\n",
    "run_seconds, run_minutes = math.modf(run_duration/60)\n",
    "print('run_duration in seconds {}'.format(run_duration))\n",
    "print('run_duration= {0:.0f}m {1:.3f}s'.format(run_minutes, run_seconds*60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing details for run 181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecf3c99f6e54422b7892e0dfeddca35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/020_AzureMLEstimator/runs/020_AzureMLEstimator_1576641205_aa71d72d?wsid=/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourcegroups/ghiordanfwirsg01/workspaces/ghiordanfwiws\", \"run_id\": \"020_AzureMLEstimator_1576641205_aa71d72d\", \"run_properties\": {\"run_id\": \"020_AzureMLEstimator_1576641205_aa71d72d\", \"created_utc\": \"2019-12-18T03:53:27.157172Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"a5071b2a-37a7-40da-8340-69cc894091cb\", \"azureml.git.repository_uri\": \"git@github.com:georgeAccnt-GH/DeepSeismic.git\", \"mlflow.source.git.repoURL\": \"git@github.com:georgeAccnt-GH/DeepSeismic.git\", \"azureml.git.branch\": \"ghiordan/azureml_devito03\", \"mlflow.source.git.branch\": \"ghiordan/azureml_devito03\", \"azureml.git.commit\": \"335e90f9a770fb28b62e509c433421a92cbb8934\", \"mlflow.source.git.commit\": \"335e90f9a770fb28b62e509c433421a92cbb8934\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2019-12-18T03:55:25.640243Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576641205_aa71d72d/azureml-logs/55_azureml-execution-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt?sv=2019-02-02&sr=b&sig=SVn%2BtGC1ko6RF9S2V%2BcPrQljGBljydlDSTlRwgiY2Ng%3D&st=2019-12-18T03%3A45%3A29Z&se=2019-12-18T11%3A55%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576641205_aa71d72d/azureml-logs/65_job_prep-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt?sv=2019-02-02&sr=b&sig=9tUhIp88GxWlrx8Z%2FpNmYnxeNXF8wzQW1I3XK5U9Lpc%3D&st=2019-12-18T03%3A45%3A29Z&se=2019-12-18T11%3A55%3A29Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576641205_aa71d72d/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=ZuZAONbZA0%2FBHCGTly%2FMT8l75Epo%2FziQ0d5cmbfh95I%3D&st=2019-12-18T03%3A45%3A29Z&se=2019-12-18T11%3A55%3A29Z&sp=r\", \"azureml-logs/75_job_post-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576641205_aa71d72d/azureml-logs/75_job_post-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt?sv=2019-02-02&sr=b&sig=C7odtYllisuM4%2Fy4amWPUU%2F9P0t3yXb9pyzJiVKJi7o%3D&st=2019-12-18T03%3A45%3A29Z&se=2019-12-18T11%3A55%3A29Z&sp=r\", \"azureml-logs/process_info.json\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576641205_aa71d72d/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=YMq8lCKloWiglWxGWxgTR8yuMU6AftDEUvE71wr%2FqJQ%3D&st=2019-12-18T03%3A45%3A29Z&se=2019-12-18T11%3A55%3A29Z&sp=r\", \"azureml-logs/process_status.json\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576641205_aa71d72d/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=W4UKWaHyWa1uboGDv8fxcacMOku6iU%2BzkbjcgTLYUVk%3D&st=2019-12-18T03%3A45%3A29Z&se=2019-12-18T11%3A55%3A29Z&sp=r\", \"logs/azureml/688_azureml.log\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576641205_aa71d72d/logs/azureml/688_azureml.log?sv=2019-02-02&sr=b&sig=FXEhXZv%2Bm0UHbZQ2k7PYFWQEwZmND8rbqkdIwMFKD2I%3D&st=2019-12-18T03%3A45%3A28Z&se=2019-12-18T11%3A55%3A28Z&sp=r\", \"logs/azureml/azureml.log\": \"https://ghiordanstoragee145cef0b.blob.core.windows.net/azureml/ExperimentRun/dcid.020_AzureMLEstimator_1576641205_aa71d72d/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=OKGeQJTWen%2FksWvC13BBMsLC%2Ffq%2BGMpRa6D3azdXWAU%3D&st=2019-12-18T03%3A45%3A28Z&se=2019-12-18T11%3A55%3A28Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_fb8a31a02be2925bd1ff1e4e593f18326131dd07931d8b07ccb10c64b890038b_d.txt\"], [\"logs/azureml/688_azureml.log\"]], \"run_duration\": \"0:01:58\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"training_message01: \", \"run_id\": \"020_AzureMLEstimator_1576641205_aa71d72d\", \"categories\": [0], \"series\": [{\"data\": [\"finished experiment\"]}]}], \"run_logs\": \"2019-12-18 03:53:49,953|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2019-12-18 03:53:49,953|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2019-12-18 03:53:49,954|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2019-12-18 03:53:49,954|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2019-12-18 03:53:50,231|azureml._base_sdk_common.user_agent|DEBUG|Fetching client info from /root/.azureml/clientinfo.json\\n2019-12-18 03:53:50,232|azureml._base_sdk_common.user_agent|DEBUG|Error loading client info: [Errno 2] No such file or directory: '/root/.azureml/clientinfo.json'\\n2019-12-18 03:53:50,560|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2019-12-18 03:53:50,560|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2019-12-18 03:53:50,560|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2019-12-18 03:53:50,560|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2019-12-18 03:53:50,560|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7f535227d598> for run source hyperdrive\\n2019-12-18 03:53:51,076|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x7f534aec9510> for run source azureml.PipelineRun\\n2019-12-18 03:53:51,080|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x7f534aec9f28> for run source azureml.ReusedStepRun\\n2019-12-18 03:53:51,084|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x7f534aec9ea0> for run source azureml.StepRun\\n2019-12-18 03:53:51,088|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f53523b0bf8> for run source azureml.scriptrun\\n2019-12-18 03:53:51,089|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-18 03:53:51,094|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:51,095|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2019-12-18 03:53:51,095|azureml.core.authentication|DEBUG|Time to expire 1814375.90442 seconds\\n2019-12-18 03:53:51,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,095|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,096|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,096|azureml._base_sdk_common.service_discovery|DEBUG|Constructing mms service url in from history url environment variable None, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,096|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,096|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,096|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,125|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:51,129|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:51,135|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:51,139|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:51,144|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:51,148|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:51,148|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2019-12-18 03:53:51,149|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-18 03:53:51,149|msrest.http_logger|DEBUG|Request URL: 'https://eastus2.experiments.azureml.net/history/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runs/020_AzureMLEstimator_1576641205_aa71d72d'\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|Request method: 'GET'\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|Request headers:\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '0584c9c0-de25-4df5-a0b6-133c534975d3'\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|    'request-id': '0584c9c0-de25-4df5-a0b6-133c534975d3'\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1057-azure-x86_64-with-debian-10.1) msrest/0.6.10 azureml._restclient/core.1.0.79'\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|Request body:\\n2019-12-18 03:53:51,150|msrest.http_logger|DEBUG|None\\n2019-12-18 03:53:51,150|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-18 03:53:51,151|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-18 03:53:51,151|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-18 03:53:51,151|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-18 03:53:51,211|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|Response headers:\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'Date': 'Wed, 18 Dec 2019 03:53:51 GMT'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '0584c9c0-de25-4df5-a0b6-133c534975d3'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-18 03:53:51,212|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2019-12-18 03:53:51,213|msrest.http_logger|DEBUG|Response content:\\n2019-12-18 03:53:51,213|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 5721,\\n  \\\"rootRunId\\\": \\\"020_AzureMLEstimator_1576641205_aa71d72d\\\",\\n  \\\"experimentId\\\": \\\"8d96276b-f420-4a67-86be-f933dd3d38cd\\\",\\n  \\\"createdUtc\\\": \\\"2019-12-18T03:53:27.1571726+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"b77869a0-66f2-4288-89ef-13c10accc4dc\\\",\\n    \\\"userPuId\\\": \\\"1003000090A95868\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\\\",\\n    \\\"userTenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\",\\n    \\\"userName\\\": \\\"George Iordanescu\\\"\\n  },\\n  \\\"userId\\\": \\\"b77869a0-66f2-4288-89ef-13c10accc4dc\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": null,\\n  \\\"revision\\\": 7,\\n  \\\"runId\\\": \\\"020_AzureMLEstimator_1576641205_aa71d72d\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2019-12-18T03:53:38.4738149+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.020_AzureMLEstimator_1576641205_aa71d72d\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"a5071b2a-37a7-40da-8340-69cc894091cb\\\",\\n    \\\"azureml.git.repository_uri\\\": \\\"git@github.com:georgeAccnt-GH/DeepSeismic.git\\\",\\n    \\\"mlflow.source.git.repoURL\\\": \\\"git@github.com:georgeAccnt-GH/DeepSeismic.git\\\",\\n    \\\"azureml.git.branch\\\": \\\"ghiordan/azureml_devito03\\\",\\n    \\\"mlflow.source.git.branch\\\": \\\"ghiordan/azureml_devito03\\\",\\n    \\\"azureml.git.commit\\\": \\\"335e90f9a770fb28b62e509c433421a92cbb8934\\\",\\n    \\\"mlflow.source.git.commit\\\": \\\"335e90f9a770fb28b62e509c433421a92cbb8934\\\",\\n    \\\"azureml.git.dirty\\\": \\\"True\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"azureml_01_modelling.py\\\",\\n  \\\"target\\\": \\\"gpuclstfwi07\\\",\\n  \\\"tags\\\": {},\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": {\\n    \\\"type\\\": \\\"Notebook\\\",\\n    \\\"locationType\\\": \\\"ArtifactId\\\",\\n    \\\"location\\\": \\\"LocalUpload/020_AzureMLEstimator_1576641205_aa71d72d/030_ScaleJobsUsingAzuremL_GeophysicsTutorial_FWI_Azure_devito.ipynb\\\"\\n  },\\n  \\\"cancelUri\\\": \\\"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runId/020_AzureMLEstimator_1576641205_aa71d72d/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runId/020_AzureMLEstimator_1576641205_aa71d72d/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false,\\n  \\\"queueingInfo\\\": null\\n}\\n2019-12-18 03:53:51,218|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2019-12-18 03:53:51,218|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'a5071b2a-37a7-40da-8340-69cc894091cb', 'azureml.git.repository_uri': 'git@github.com:georgeAccnt-GH/DeepSeismic.git', 'mlflow.source.git.repoURL': 'git@github.com:georgeAccnt-GH/DeepSeismic.git', 'azureml.git.branch': 'ghiordan/azureml_devito03', 'mlflow.source.git.branch': 'ghiordan/azureml_devito03', 'azureml.git.commit': '335e90f9a770fb28b62e509c433421a92cbb8934', 'mlflow.source.git.commit': '335e90f9a770fb28b62e509c433421a92cbb8934', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2019-12-18 03:53:51,218|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2019-12-18 03:53:51,219|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2019-12-18 03:53:51,219|azureml.WorkerPool|DEBUG|[START]\\n2019-12-18 03:53:51,219|azureml.SendRunKillSignal|DEBUG|[START]\\n2019-12-18 03:53:51,219|azureml.RunStatusContext|DEBUG|[START]\\n2019-12-18 03:53:51,219|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunContextManager.RunStatusContext|DEBUG|[START]\\n2019-12-18 03:53:51,219|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2019-12-18 03:53:51,219|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2019-12-18 03:53:51,219|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/ghiordanfwiws/azureml/020_azuremlestimator_1576641205_aa71d72d/mounts/workspaceblobstore/azureml/020_AzureMLEstimator_1576641205_aa71d72d\\n2019-12-18 03:53:51,219|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2019-12-18 03:53:51,219|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/ghiordanfwiws/azureml/020_azuremlestimator_1576641205_aa71d72d/mounts/workspaceblobstore/azureml/020_AzureMLEstimator_1576641205_aa71d72d\\n2019-12-18 03:53:53,104|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,104|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,104|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,104|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,105|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,105|azureml._base_sdk_common.service_discovery|DEBUG|Constructing mms service url in from history url environment variable None, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,105|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,105|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,105|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2019-12-18 03:53:53,110|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:53,111|azureml._run_impl.run_history_facade|DEBUG|Created a static thread pool for RunHistoryFacade class\\n2019-12-18 03:53:53,115|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:53,120|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:53,124|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:53,128|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:53:53,129|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2019-12-18 03:53:53,129|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-18 03:53:53,129|msrest.http_logger|DEBUG|Request URL: 'https://eastus2.experiments.azureml.net/history/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runs/020_AzureMLEstimator_1576641205_aa71d72d'\\n2019-12-18 03:53:53,129|msrest.http_logger|DEBUG|Request method: 'GET'\\n2019-12-18 03:53:53,129|msrest.http_logger|DEBUG|Request headers:\\n2019-12-18 03:53:53,129|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-18 03:53:53,129|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-18 03:53:53,129|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '5eef3ce8-6e03-46f3-8eb4-7e7beb90d699'\\n2019-12-18 03:53:53,129|msrest.http_logger|DEBUG|    'request-id': '5eef3ce8-6e03-46f3-8eb4-7e7beb90d699'\\n2019-12-18 03:53:53,129|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1057-azure-x86_64-with-debian-10.1) msrest/0.6.10 azureml._restclient/core.1.0.79'\\n2019-12-18 03:53:53,130|msrest.http_logger|DEBUG|Request body:\\n2019-12-18 03:53:53,130|msrest.http_logger|DEBUG|None\\n2019-12-18 03:53:53,130|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-18 03:53:53,130|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-18 03:53:53,130|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-18 03:53:53,130|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-18 03:53:53,207|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|Response headers:\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'Date': 'Wed, 18 Dec 2019 03:53:53 GMT'\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '5eef3ce8-6e03-46f3-8eb4-7e7beb90d699'\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-18 03:53:53,208|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-18 03:53:53,209|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2019-12-18 03:53:53,209|msrest.http_logger|DEBUG|Response content:\\n2019-12-18 03:53:53,209|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 5721,\\n  \\\"rootRunId\\\": \\\"020_AzureMLEstimator_1576641205_aa71d72d\\\",\\n  \\\"experimentId\\\": \\\"8d96276b-f420-4a67-86be-f933dd3d38cd\\\",\\n  \\\"createdUtc\\\": \\\"2019-12-18T03:53:27.1571726+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"b77869a0-66f2-4288-89ef-13c10accc4dc\\\",\\n    \\\"userPuId\\\": \\\"1003000090A95868\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\\\",\\n    \\\"userTenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\",\\n    \\\"userName\\\": \\\"George Iordanescu\\\"\\n  },\\n  \\\"userId\\\": \\\"b77869a0-66f2-4288-89ef-13c10accc4dc\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": null,\\n  \\\"revision\\\": 7,\\n  \\\"runId\\\": \\\"020_AzureMLEstimator_1576641205_aa71d72d\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2019-12-18T03:53:38.4738149+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.020_AzureMLEstimator_1576641205_aa71d72d\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"a5071b2a-37a7-40da-8340-69cc894091cb\\\",\\n    \\\"azureml.git.repository_uri\\\": \\\"git@github.com:georgeAccnt-GH/DeepSeismic.git\\\",\\n    \\\"mlflow.source.git.repoURL\\\": \\\"git@github.com:georgeAccnt-GH/DeepSeismic.git\\\",\\n    \\\"azureml.git.branch\\\": \\\"ghiordan/azureml_devito03\\\",\\n    \\\"mlflow.source.git.branch\\\": \\\"ghiordan/azureml_devito03\\\",\\n    \\\"azureml.git.commit\\\": \\\"335e90f9a770fb28b62e509c433421a92cbb8934\\\",\\n    \\\"mlflow.source.git.commit\\\": \\\"335e90f9a770fb28b62e509c433421a92cbb8934\\\",\\n    \\\"azureml.git.dirty\\\": \\\"True\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"azureml_01_modelling.py\\\",\\n  \\\"target\\\": \\\"gpuclstfwi07\\\",\\n  \\\"tags\\\": {},\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": {\\n    \\\"type\\\": \\\"Notebook\\\",\\n    \\\"locationType\\\": \\\"ArtifactId\\\",\\n    \\\"location\\\": \\\"LocalUpload/020_AzureMLEstimator_1576641205_aa71d72d/030_ScaleJobsUsingAzuremL_GeophysicsTutorial_FWI_Azure_devito.ipynb\\\"\\n  },\\n  \\\"cancelUri\\\": \\\"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runId/020_AzureMLEstimator_1576641205_aa71d72d/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runId/020_AzureMLEstimator_1576641205_aa71d72d/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false,\\n  \\\"queueingInfo\\\": null\\n}\\n2019-12-18 03:53:53,211|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2019-12-18 03:53:53,211|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'a5071b2a-37a7-40da-8340-69cc894091cb', 'azureml.git.repository_uri': 'git@github.com:georgeAccnt-GH/DeepSeismic.git', 'mlflow.source.git.repoURL': 'git@github.com:georgeAccnt-GH/DeepSeismic.git', 'azureml.git.branch': 'ghiordan/azureml_devito03', 'mlflow.source.git.branch': 'ghiordan/azureml_devito03', 'azureml.git.commit': '335e90f9a770fb28b62e509c433421a92cbb8934', 'mlflow.source.git.commit': '335e90f9a770fb28b62e509c433421a92cbb8934', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2019-12-18 03:53:53,212|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2019-12-18 03:54:21,090|azureml.core.authentication|DEBUG|Time to expire 1814345.909671 seconds\\n2019-12-18 03:54:51,091|azureml.core.authentication|DEBUG|Time to expire 1814315.908961 seconds\\n2019-12-18 03:55:03,497|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2019-12-18 03:55:03,497|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-18 03:55:03,497|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2019-12-18 03:55:03,630|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2019-12-18 03:55:03,630|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /devito\\n2019-12-18 03:55:03,630|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|pyfs has path /devito\\n2019-12-18 03:55:03,630|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /devito to /mnt/batch/tasks/shared/LS_root/jobs/ghiordanfwiws/azureml/020_azuremlestimator_1576641205_aa71d72d/mounts/workspaceblobstore/azureml/020_AzureMLEstimator_1576641205_aa71d72d\\n2019-12-18 03:55:03,630|azureml.history._tracking.PythonWorkingDirectory|INFO|Setting working dir to /mnt/batch/tasks/shared/LS_root/jobs/ghiordanfwiws/azureml/020_azuremlestimator_1576641205_aa71d72d/mounts/workspaceblobstore/azureml/020_AzureMLEstimator_1576641205_aa71d72d\\n2019-12-18 03:55:03,631|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2019-12-18 03:55:03,631|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2019-12-18 03:55:03,631|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d|INFO|complete is not setting status for submitted runs.\\n2019-12-18 03:55:03,631|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-18 03:55:03,631|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2019-12-18 03:55:03,631|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2019-12-18 03:55:03,632|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2019-12-18 03:55:03,632|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-18 03:55:03,632|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2019-12-18 03:55:03,632|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2019-12-18 03:55:03,632|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2019-12-18 03:55:03,632|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-18 03:55:03,632|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-18 03:55:03,632|azureml.RunStatusContext|DEBUG|[STOP]\\n2019-12-18 03:55:03,633|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-18 03:55:03,633|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-18 03:55:03,633|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2019-12-18 03:55:03,633|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2019-12-18 03:55:03,633|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2019-12-18 03:55:03,633|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-18 03:55:03,633|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-18 03:55:03,633|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2019-12-18 03:55:03,633|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2019-12-18 03:55:03,634|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2019-12-18 03:55:03,634|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 1.\\n2019-12-18 03:55:03,634|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2019-12-18 03:55:03,634|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2019-12-18 03:55:03,634|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2019-12-18 03:55:03,635|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch|DEBUG|Using basic handler - no exception handling\\n2019-12-18 03:55:03,635|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2019-12-18 03:55:03,635|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2019-12-18 03:55:03,635|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 0__log_batch to queue of approximate size: 0\\n2019-12-18 03:55:03,636|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2019-12-18 03:55:03,636|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2019-12-18 03:55:03,637|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2019-12-18 03:55:03,637|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2019-12-18 03:55:03,637|msrest.http_logger|DEBUG|Request URL: 'https://eastus2.experiments.azureml.net/history/v1.0/subscriptions/789908e0-5fc2-4c4d-b5f5-9764b0d602b3/resourceGroups/ghiordanfwirsg01/providers/Microsoft.MachineLearningServices/workspaces/ghiordanfwiws/experiments/020_AzureMLEstimator/runs/020_AzureMLEstimator_1576641205_aa71d72d/batch/metrics'\\n2019-12-18 03:55:03,637|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2019-12-18 03:55:03,637|msrest.http_logger|DEBUG|Request method: 'POST'\\n2019-12-18 03:55:03,637|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2019-12-18 03:55:03,638|msrest.http_logger|DEBUG|Request headers:\\n2019-12-18 03:55:03,638|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2019-12-18 03:55:03,638|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2019-12-18 03:55:03,638|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2019-12-18 03:55:03,638|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2019-12-18 03:55:03,638|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2019-12-18 03:55:03,638|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'c3ed59b5-cecd-48f2-9640-db3eb82cfbc4'\\n2019-12-18 03:55:03,638|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2019-12-18 03:55:03,638|msrest.http_logger|DEBUG|    'request-id': 'c3ed59b5-cecd-48f2-9640-db3eb82cfbc4'\\n2019-12-18 03:55:03,639|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2019-12-18 03:55:03,639|msrest.http_logger|DEBUG|    'Content-Length': '410'\\n2019-12-18 03:55:03,639|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2019-12-18 03:55:03,639|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1057-azure-x86_64-with-debian-10.1) msrest/0.6.10 azureml._restclient/core.1.0.79 sdk_run'\\n2019-12-18 03:55:03,639|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [AsyncTask(0__log_batch)].\\n2019-12-18 03:55:03,639|msrest.http_logger|DEBUG|Request body:\\n2019-12-18 03:55:03,639|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"91fbac36-3af1-45bd-b8e1-cd5376d16624\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2019-12-18T03:55:03.496961Z\\\", \\\"name\\\": \\\"training_message01: \\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"training_message01: \\\": \\\"finished experiment\\\"}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"training_message01: \\\", \\\"name\\\": \\\"training_message01: \\\", \\\"type\\\": \\\"string\\\"}]}}]}\\n2019-12-18 03:55:03,639|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2019-12-18 03:55:03,640|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2019-12-18 03:55:03,640|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2019-12-18 03:55:03,640|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2019-12-18 03:55:03,785|msrest.http_logger|DEBUG|Response status: 200\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|Response headers:\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|    'Date': 'Wed, 18 Dec 2019 03:55:03 GMT'\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'c3ed59b5-cecd-48f2-9640-db3eb82cfbc4'\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|Response content:\\n2019-12-18 03:55:03,786|msrest.http_logger|DEBUG|\\n2019-12-18 03:55:03,788|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2019-12-18 03:55:03,890|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|[START]\\n2019-12-18 03:55:03,890|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|Awaiter is PostMetricsBatch\\n2019-12-18 03:55:03,890|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|[STOP]\\n2019-12-18 03:55:03,890|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Waiting on task: 0__log_batch.\\n1 tasks left. Current duration of flush 0.0002357959747314453 seconds.\\n\\n2019-12-18 03:55:03,890|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2019-12-18 03:55:03,890|azureml._SubmittedRun#020_AzureMLEstimator_1576641205_aa71d72d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2019-12-18 03:55:03,890|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2019-12-18 03:55:03,890|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2019-12-18 03:55:03,890|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2019-12-18 03:55:03,890|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"NOTSET\", \"sdk_version\": \"1.0.76\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter182: submission of job 182 on 20 nodes took 9.67591118812561 seconds \n",
      "run list length 182\n",
      "Counter183: submission of job 183 on 20 nodes took 8.417665958404541 seconds \n",
      "run list length 183\n",
      "Counter184: submission of job 184 on 20 nodes took 8.162678956985474 seconds \n",
      "run list length 184\n",
      "Counter185: submission of job 185 on 20 nodes took 8.167269706726074 seconds \n",
      "run list length 185\n",
      "Counter186: submission of job 186 on 20 nodes took 7.944813966751099 seconds \n",
      "run list length 186\n",
      "Counter187: submission of job 187 on 20 nodes took 9.100224256515503 seconds \n",
      "run list length 187\n",
      "Counter188: submission of job 188 on 20 nodes took 8.355362892150879 seconds \n",
      "run list length 188\n",
      "Counter189: submission of job 189 on 20 nodes took 9.092441320419312 seconds \n",
      "run list length 189\n",
      "Counter190: submission of job 190 on 20 nodes took 10.007514238357544 seconds \n",
      "run list length 190\n",
      "Counter191: submission of job 191 on 20 nodes took 8.018926858901978 seconds \n",
      "run list length 191\n",
      "Counter192: submission of job 192 on 20 nodes took 8.925177574157715 seconds \n",
      "run list length 192\n",
      "Counter193: submission of job 193 on 20 nodes took 8.075469493865967 seconds \n",
      "run list length 193\n",
      "Counter194: submission of job 194 on 20 nodes took 8.114925384521484 seconds \n",
      "run list length 194\n",
      "Counter195: submission of job 195 on 20 nodes took 11.568782329559326 seconds \n",
      "run list length 195\n",
      "Counter196: submission of job 196 on 20 nodes took 7.691022157669067 seconds \n",
      "run list length 196\n",
      "Counter197: submission of job 197 on 20 nodes took 7.677650451660156 seconds \n",
      "run list length 197\n",
      "Counter198: submission of job 198 on 20 nodes took 7.701624393463135 seconds \n",
      "run list length 198\n",
      "Counter199: submission of job 199 on 20 nodes took 8.586235761642456 seconds \n",
      "run list length 199\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "no_of_nodes = int(20)\n",
    "no_of_jobs = int(no_of_nodes*10)\n",
    "\n",
    "\n",
    "job_counter = 0\n",
    "print_cycle = 20\n",
    "run_list = []\n",
    "submit_time_list = []\n",
    "for crt_nodes in range(no_of_nodes, (no_of_nodes+1)):\n",
    "    gpu_cluster.update(min_nodes=0, max_nodes=crt_nodes, idle_seconds_before_scaledown=1200)\n",
    "    clust_start_time = time.time()\n",
    "    for crt_job in range(1, no_of_jobs):\n",
    "        job_counter+= 1\n",
    "        start_time = time.time()\n",
    "        run = exp.submit(est)\n",
    "        end_time = time.time()\n",
    "        run_time = end_time - start_time\n",
    "        run_list.append(run)\n",
    "        submit_time_list.append(run_time)\n",
    "        print('Counter{}: submission of job {} on {} nodes took {} seconds '.format(job_counter, crt_job, crt_nodes, run_time))\n",
    "        print('run list length {}'.format(len(run_list)))\n",
    "        if ((job_counter-1) % print_cycle) == 0:\n",
    "            clear_output()\n",
    "            print('Showing details for run {}'.format(job_counter))\n",
    "            RunDetails(run).show()\n",
    "#     [all_jobs_done = True if (('Completed'==crt_queried_job.get_status()) for crt_queried_job in run_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72.32372785,  9.84876561,  8.23770022,  8.51928997, 10.07481861,\n",
       "        9.50573421,  8.61487699,  9.2067368 ,  8.7046783 ,  8.50711679,\n",
       "       10.19562602,  9.36683083,  7.55569768,  7.81828165,  8.05966425,\n",
       "        7.95713139,  8.46397591,  8.00363493,  8.74197745,  9.85158968,\n",
       "        8.15499783,  8.4186945 ,  8.3459394 ,  7.77093124, 10.68578815,\n",
       "        8.50453854, 10.00224447,  7.92351389,  8.35350633,  9.25221825,\n",
       "        8.34743953,  7.69802356,  8.29426646,  8.59166431,  8.46652174,\n",
       "        9.47893   , 75.07776022,  8.41120005,  8.96823859, 10.98724246,\n",
       "        7.94364333,  7.90829492,  8.94897985, 10.17237568,  9.11909747,\n",
       "        7.87749696,  8.00650215,  8.36645675,  8.91567326, 10.34763336,\n",
       "        7.77076221,  7.88283515,  7.75079894,  9.26020312,  8.62849283,\n",
       "        7.80995584,  7.80822968, 10.76239038,  8.14607382,  7.99221134,\n",
       "        9.6921885 ,  8.19335723,  9.15633559,  8.00351334,  9.54636669,\n",
       "        7.59108806,  7.69910932,  8.04463506,  7.93083286,  8.62544155,\n",
       "        8.79564786,  9.13332033,  7.80911231,  8.35303783,  7.82778549,\n",
       "        8.06088972,  9.1007092 ,  8.3380692 ,  8.64629507,  8.07920575,\n",
       "        8.02019548, 10.71363115,  8.34652901,  7.74129391,  7.91959643,\n",
       "        7.85336089,  7.90019083, 12.90023398, 19.41495585, 13.15474701,\n",
       "       12.07031298, 11.95169044,  7.79440594, 10.60236144,  8.72420573,\n",
       "        8.06074238,  8.54056549,  8.02011943,  9.75681472,  8.5499773 ,\n",
       "        7.79605484,  8.42818856,  9.18867898,  7.9006598 , 27.39237142,\n",
       "        9.0595603 ,  8.78542948,  7.90973282,  8.57101846,  8.46719694,\n",
       "        8.13528228,  8.01672626,  8.10046387,  9.75899887,  8.07786036,\n",
       "        8.67664742,  8.93552232,  9.15524864,  9.84150887, 10.98953986,\n",
       "        7.7957077 ,  8.00527406,  8.84030366,  8.21525049,  8.41219711,\n",
       "        8.58533263,  9.19599056,  8.0582397 ,  9.54104137,  7.90521908,\n",
       "        9.04605484,  9.31400728,  8.40495944,  9.40762448,  8.44924903,\n",
       "        8.32500076,  9.12283754,  7.8790009 ,  7.81203079,  9.60578918,\n",
       "        8.49342728,  8.78831935,  8.37885499,  7.84795952,  8.0113368 ,\n",
       "       10.01567674,  8.65693212,  7.91696692,  8.66499114,  8.16211271,\n",
       "       10.52479053,  8.01505375,  7.76023841,  8.17951965,  8.72431993,\n",
       "        8.06374121,  8.10564208,  8.59537721,  9.92992234,  8.32705522,\n",
       "        9.78222585,  9.35200691,  9.76717973, 10.28895092,  9.19370604,\n",
       "        8.0294354 ,  8.37053967,  9.8634398 ,  8.63042641,  8.18737698,\n",
       "       43.09095621,  8.65846062, 10.26536632,  8.97337079,  8.09767246,\n",
       "       11.08810735,  9.55694532, 15.43015337, 12.9441483 , 74.00292444,\n",
       "        8.60825634,  9.67591119,  8.41766596,  8.16267896,  8.16726971,\n",
       "        7.94481397,  9.10022426,  8.35536289,  9.09244132, 10.00751424,\n",
       "        8.01892686,  8.92517757,  8.07546949,  8.11492538, 11.56878233,\n",
       "        7.69102216,  7.67765045,  7.70162439,  8.58623576])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0,  0,  0, 12, 61, 44, 20, 19, 13]),\n",
       " array([ 6.        ,  6.44444444,  6.88888889,  7.33333333,  7.77777778,\n",
       "         8.22222222,  8.66666667,  9.11111111,  9.55555556, 10.        ]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.asarray(submit_time_list)\n",
    "np.histogram(np.asarray(submit_time_list), bins=np.linspace(6.0, 10.0, num=10), density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final print 40, time 119.696 seconds: Counter({'Completed': 184, 'Failed': 15})izing': 1})Running': 1})\r"
     ]
    }
   ],
   "source": [
    "def wait_for_run_list_to_finish(the_run_list, plot_results=True):\n",
    "    finished_status_list = ['Completed', 'Failed']\n",
    "    printing_counter = 0\n",
    "    start_time = time.time()\n",
    "    while (not all((crt_queried_job.get_status() in finished_status_list) for crt_queried_job in the_run_list)):\n",
    "        time.sleep(2)\n",
    "        printing_counter+= 1\n",
    "        crt_status = Counter([crt_queried_job.get_status() for crt_queried_job in the_run_list])\n",
    "        print('print {0:.0f}, time {1:.3f} seconds: {2}'.format(printing_counter, time.time() - start_time, \n",
    "                                str(crt_status)), end=\"\\r\")\n",
    "        if plot_results:\n",
    "#           import numpy as np\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.bar(crt_status.keys(), crt_status.values())\n",
    "            plt.show()\n",
    "            \n",
    "#             indexes = np.arange(len(labels))\n",
    "#             width = 1\n",
    "\n",
    "#             plt.bar(indexes, values, width)\n",
    "#             plt.xticks(indexes + width * 0.5, labels)\n",
    "#             plt.show()\n",
    "\n",
    "#             from pandas import Series\n",
    "#             crt_status = Series([crt_queried_job.get_status() for crt_queried_job in the_run_list])\n",
    "#             status_counts = crt_status.value_counts().sort_index()\n",
    "#             print('print {0:.0f}, time {1:.3f} seconds: {2}'.format(printing_counter, time.time() - start_time, \n",
    "#                                 str(status_counts)), end=\"\\r\")\n",
    "#     final status\n",
    "    print('Final print {0:.0f}, time {1:.3f} seconds: {2}'.format(printing_counter, time.time() - start_time, \n",
    "                                str(Counter([crt_queried_job.get_status() for crt_queried_job in the_run_list]))), end=\"\\r\")     \n",
    "\n",
    "wait_for_run_list_to_finish(run_list, plot_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_durations = [get_run_duration(crt_queried_job) for crt_queried_job in run_list]\n",
    "run_statuses = [crt_queried_job.get_status() for crt_queried_job in run_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 76, 160,  87, 148, 146,  78, 140, 122,   6,  34, 192,  27,  74,\n",
       "        94,   9, 169,  82, 152,  89,  38])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117.302675 117.403537 117.598663 117.907701 119.020195 122.495359\n",
      " 128.828526 131.806861 132.140995 159.631798 166.340537 166.637734\n",
      " 166.748339 169.732802 170.608667 170.923515 171.960079 186.075458\n",
      " 213.533596 223.50992 ]\n",
      "['Completed' 'Completed' 'Completed' 'Completed' 'Completed' 'Completed'\n",
      " 'Completed' 'Completed' 'Completed' 'Completed' 'Completed' 'Completed'\n",
      " 'Completed' 'Completed' 'Completed' 'Completed' 'Completed' 'Completed'\n",
      " 'Completed' 'Failed']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 43, 125, 136,  85, 147, 195, 183,  50, 174, 116,  45,  23, 112,\n",
       "       100,  72,  25, 120,  93,  98,  77])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94.171413  97.399767  99.25924   99.408774  99.514601  99.538883\n",
      "  99.752909  99.831267 100.191572 100.296421 100.401819 100.462001\n",
      " 100.867313 100.895425 100.990763 101.042026 101.110186 101.184303\n",
      " 101.320054 101.384652]\n",
      "['Failed' 'Completed' 'Completed' 'Failed' 'Completed' 'Completed'\n",
      " 'Failed' 'Completed' 'Completed' 'Completed' 'Failed' 'Completed'\n",
      " 'Completed' 'Completed' 'Completed' 'Completed' 'Completed' 'Completed'\n",
      " 'Completed' 'Completed']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   8, 169,  11,   0,   3,   5,   1]),\n",
       " array([ 50.        ,  66.66666667,  83.33333333, 100.        ,\n",
       "        116.66666667, 133.33333333, 150.        , 166.66666667,\n",
       "        183.33333333, 200.        ]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_durations = np.asarray(run_durations)\n",
    "run_statuses = np.asarray(run_statuses)\n",
    "\n",
    "extreme_k = 20\n",
    "#longest runs\n",
    "indices = np.argsort(run_durations)[-extreme_k:]\n",
    "indices\n",
    "print(run_durations[indices])\n",
    "print(run_statuses[indices])\n",
    "#shortest runs\n",
    "indices = np.argsort(run_durations)[0:extreme_k]\n",
    "indices\n",
    "print(run_durations[indices])\n",
    "print(run_statuses[indices])\n",
    "\n",
    "#run_durations histogram - counts and bins\n",
    "np.histogram(run_durations, bins=np.linspace(50, 200, num=10), density=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running 030_ScaleJobsUsingAzuremL_GeophysicsTutorial_FWI_Azure_devito!\n"
     ]
    }
   ],
   "source": [
    "print('Finished running 030_ScaleJobsUsingAzuremL_GeophysicsTutorial_FWI_Azure_devito!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fwi_dev_conda_environment Python",
   "language": "python",
   "name": "fwi_dev_conda_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
