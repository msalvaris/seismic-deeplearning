# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

# Pull request against these branches will trigger this build
pr:
- master
- staging

# Any commit to this branch will trigger the build.
trigger:
- master
- staging

jobs:
# partially disable setup for now - done manually on build VM
- job: setup
  timeoutInMinutes: 5
  displayName: Setup

  pool:
    name: deepseismicagentpool

  steps:
  - bash: |
      echo "Running setup..."
      pwd
      ls
      git branch
      uname -ra

      # make sure we have the latest and greatest
      # yes | conda env update -f environment/anaconda/local/environment.yml
      conda activate seismic-interpretation
      pip install -e interpretation
      pip install -e cv_lib
      # add this if pytorch stops detecting GPU
      # conda install pytorch torchvision cudatoolkit=9.2 -c pytorch
  
      # copy your model files like so - using dummy file to illustrate
      azcopy --quiet --source:https://$(storagename).blob.core.windows.net/models/model --source-key $(storagekey) --destination /home/alfred/models/your_model_name

- job: unit_tests_job
  timeoutInMinutes: 20
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      echo "Starting unit tests"
      conda activate seismic-interpretation
      pytest --durations=0 cv_lib/tests/
      echo "Unit test job passed"
    displayName: Unit Tests Job

###################################################################################################
# LOCAL PATCH JOBS
###################################################################################################

- job: hrnet_patch
  timeoutInMinutes: 5
  displayName: hrnet patch
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local
      python train.py --cfg=configs/hrnet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      # find the latest model which we just trained
      model=$(ls -td */*/*/hrnet/* | head -1)
      # try running the test script
      python test.py --cfg=configs/hrnet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/models/hrnet_running_model_1.pth

- job: unet_patch
  timeoutInMinutes: 5
  displayName: unet patch
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local
      python train.py --cfg=configs/unet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      # find the latest model which we just trained
      model=$(ls -td */*/*/unet/* | head -1)
      # try running the test script
      python test.py --cfg=configs/unet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/models/unet_running_model_1.pth

- job: seresnet_unet_patch
  timeoutInMinutes: 5
  displayName: seresnet unet patch
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local
      python train.py --cfg=configs/seresnet_unet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      # find the latest model which we just trained
      model=$(ls -td */*/*/seresnet_unet/* | head -1)
      # try running the test script
      python test.py --cfg=configs/seresnet_unet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/models/seresnet_unet_running_model_1.pth

- job: patch_deconvnet
  timeoutInMinutes: 5
  displayName: patch deconvnet
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local
      python train.py --cfg=configs/patch_deconvnet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      # find the latest model which we just trained
      model=$(ls -td */*/*/patch_deconvnet/* | head -1)
      # try running the test script
      python test.py --cfg=configs/patch_deconvnet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/models/patch_deconvnet_running_model_1.pth

- job: patch_deconvnet_skip
  timeoutInMinutes: 5
  displayName: patch deconvnet skip
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/local
      python train.py --cfg=configs/patch_deconvnet_skip.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      # find the latest model which we just trained
      model=$(ls -td */*/*/patch_deconvnet_skip/* | head -1)
      # try running the test script
      python test.py --cfg=configs/patch_deconvnet_skip.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/models/patch_deconvnet_skip_running_model_1.pth

# Penobscot dataset

- job: seresnet_unet
  timeoutInMinutes: 5
  displayName: seresnet unet
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/penobscot/local
      python train.py --cfg=configs/seresnet_unet.yaml 'DATASET.ROOT' '/home/alfred/data/penobscot' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      # find the latest model which we just trained
      model=$(ls -td */*/*/seresnet_unet/* | head -1)
      # try running the test script
      python test.py --cfg=configs/seresnet_unet.yaml 'DATASET.ROOT' '/home/alfred/data/penobscot' 'TEST.MODEL_PATH' ${model}/models/seresnet_unet_running_model_1.pth

- job: hrnet_penobscot
  timeoutInMinutes: 5
  displayName: hrnet penobscot
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/penobscot/local
      python train.py --cfg=configs/hrnet.yaml 'DATASET.ROOT' '/home/alfred/data/penobscot' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      # find the latest model which we just trained
      model=$(ls -td */*/*/hrnet/* | head -1)
      # try running the test script
      python test.py --cfg=configs/hrnet.yaml 'DATASET.ROOT' '/home/alfred/data/penobscot' 'TEST.MODEL_PATH' ${model}/models/hrnet_running_model_1.pth

###################################################################################################
# DISTRIBUTED PATCH JOBS
###################################################################################################

- job: hrnet_patch
  timeoutInMinutes: 5
  displayName: hrnet patch
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      export PYTHONPATH="$PWD/interpretation:$PYTHONPATH"
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py --cfg=configs/hrnet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1

- job: unet_patch
  timeoutInMinutes: 5
  displayName: unet patch
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      export PYTHONPATH="$PWD/interpretation:$PYTHONPATH"
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py --cfg=configs/unet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1      

- job: seresnet_unet_patch
  timeoutInMinutes: 5
  displayName: seresnet unet patch
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      export PYTHONPATH="$PWD/interpretation:$PYTHONPATH"
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py --cfg=configs/seresnet_unet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      
- job: patch_deconvnet
  timeoutInMinutes: 5
  displayName: patch deconvnet
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      export PYTHONPATH="$PWD/interpretation:$PYTHONPATH"
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py --cfg=configs/patch_deconvnet.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1  

- job: patch_deconvnet_skip
  timeoutInMinutes: 5
  displayName: patch deconvnet skip
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      export PYTHONPATH="$PWD/interpretation:$PYTHONPATH"
      # run the tests      
      cd experiments/interpretation/dutchf3_patch/distributed
      python -m torch.distributed.launch --nproc_per_node=$(nproc) train.py --cfg=configs/patch_deconvnet_skip.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1


###################################################################################################
# LOCAL SECTION JOBS
###################################################################################################

- job: section_deconvnet_skip
  timeoutInMinutes: 5
  displayName: section deconvnet skip
  pool:
    name: deepseismicagentpool
  steps:
  - bash: |
      conda activate seismic-interpretation
      # run the tests      
      cd experiments/interpretation/dutchf3_section/local
      python train.py --cfg=configs/section_deconvnet_skip.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TRAIN.END_EPOCH' 1 'TRAIN.SNAPSHOTS' 1
      # find the latest model which we just trained
      model=$(ls -td */*/*/section_deconvnet_skip/* | head -1)
      # try running the test script
      python test.py --cfg=configs/section_deconvnet_skip.yaml 'DATASET.ROOT' '/home/alfred/data/dutch_f3/data' 'TEST.MODEL_PATH' ${model}/models/section_deconvnet_skip_running_model_1.pth

